}
}
## Step 1.2: read excel and convert to csv
if(file_format == "xlsx"){
file.list <- lapply(files, read.xlsx, sheet = 1, rowNames = TRUE, colNames = TRUE, skipEmptyRows = TRUE, skipEmptyCols = TRUE, na.strings = "NA")
}
## Step 1.3: load csv data
if(file_format == "csv"){
file.list <- lapply(files, read_csv, col_names = TRUE)
}
## Step 1.4: load tsv or txt data
if(file_format == "tsv" | file_format == "txt"){
file.list <- lapply(files, read_tsv, col_names = TRUE)
}
View(file.list)
View(file.list)
View(file.list[[1]])
View(file.list[[2]])
?read_tsv
## Step 1.4: load tsv or txt data
if(file_format == "tsv" | file_format == "txt"){
file.list <- lapply(files, read_tsv, na = c("", "NA"), col_names = TRUE)
}
View(file.list[[1]])
## Step 1.4: load tsv or txt data
if(file_format == "tsv" | file_format == "txt"){
file.list <- lapply(files, read_tsv, na = c("", "NA"), col_names = TRUE)
}
## Step 1.4: load tsv or txt data
if(file_format == "tsv" | file_format == "txt"){
file.list <- lapply(files, read_tsv, na = c("", "NA"), quoted_na = FALSE, col_names = TRUE)
}
View(file.list[[1]])
## Step 1.4: load tsv or txt data
if(file_format == "tsv" | file_format == "txt"){
file.list <- lapply(files, read_table, na = c("", "NA"), quoted_na = FALSE, col_names = TRUE)
}
## Step 1.4: load tsv or txt data
if(file_format == "tsv" | file_format == "txt"){
file.list <- lapply(files, read_table, na = c("", "NA"), col_names = TRUE)
}
View(file.list[[1]])
?read_table
## Step 1.4: load tsv or txt data
if(file_format == "tsv" | file_format == "txt"){
file.list <- lapply(files, read_table2, na = c("", "NA"), col_names = TRUE)
}
View(file.list[[1]])
## Step 1.4: load tsv or txt data
if(file_format == "tsv" | file_format == "txt"){
file.list <- lapply(files, read_table, na = c("", "NA"), col_names = TRUE)
}
View(file.list[[1]])
## Step 1.4: load tsv or txt data
if(file_format == "tsv" | file_format == "txt"){
file.list <- lapply(files, read_table, na = "NA", col_names = TRUE)
}
View(file.list[[1]])
?tk_messageBox
# Ask user whether input is in Shimatzu format
form <- tk_messageBox(type = "yesno", message = "Are the selected .xlsx files already in the standard 3 tab format. \n\nYES: Theses are manually curated files of correct format.  \n\nNo: The files are in Shimadzu format and need adjustment."
, caption = "Question", default = "")
is.na(form)
exists(df)
exists(form)
exists("form")
exists("df")
exists("test")
exists("h")
# GUI to allow user to select file cnating weights
filters <- matrix(c("All accepted",".tsv .txt .csv .xlsx", "Tab seperated files",".tsv","Excel files" ,".xlsx","Text files",".txt", "All files", "*"), 5, 2, byrow = TRUE)
list.of.packages = c("here","tidyverse","knitr","tcltk","readxl","matrixStats","openxlsx","tools","stringr","utils","pdftools","ggplot2","ggpubr","BBmisc","ggsci","scales","RColorBrewer")
list.of.packages = c("here","tidyverse","knitr","tcltk","readxl","matrixStats","openxlsx","tools","stringr","utils","pdftools","ggplot2","ggpubr","BBmisc","ggsci","scales","RColorBrewer")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages) > 0) {install.packages(new.packages)}
lapply(list.of.packages, require, character.only=T)
# Date
date <- format(Sys.Date(), format="%Y-%m-%d")
# GUI to allow user to selection working directory
wd <- tk_choose.dir(here(), caption = "Select your working directory")
# GUI to allow user to selection working directory
wd <- tk_choose.dir(here(), caption = "Select your working directory")
setwd(wd)
# Name of the output directory (will be created in your current working directory)
outfolder <- file.path(str_c(date,"_GCSM-analysis-results"))
# create output dir
dir.create(outfolder)
# GUI to allow user selection
filters <- matrix(c("All accepted",".pdf .tsv .csv .xlsx .txt", "PDF files",".pdf","Comma seperated files",".csv","Tab seperated files",".tsv","Excel files" ,".xlsx","Text files",".txt", "All files", "*"), 7, 2, byrow = TRUE)
files <- tk_choose.files(caption = "Choose GCMS files to analyse", multi = TRUE, filter = filters)
# identify file type by extension
ext <- file_ext(files)
file_format <- unique(ext)
for (file in 1:length(files)){
# Report error if file format is wrong
if(!(ext[[file]] %in% c("pdf","xlsx","tsv","csv","txt")) ){
stop(str_c("Incorrect extension of file ",file,": Please select only files of supported format (.pdf,.xlsx,.tsv,.csv,.txt)."))
}
# Report error if not all files are of same format
if(length(file_format) > 1){
stop(str_c("Inconsitent file extensions. All files must be of same file format."))
}
}
## Step 1.1: read pdf and convert to tsv
if(file_format == "pdf"){
for (file in 1:length(files)){
# read pdf file and split into rows
pages <- pdf_text(files[file]) %>% strsplit(split = "\n")
# set read to default ("no")
read <- "no"
# set run counter to 0
run <- 0
# go through the pages and extract table information
for (p in 1:length(pages)){
# select text from a page
page.text<-pages[p][[1]]
#identify start position for text extraction based on grep result
start_pos <- tail(grep("Compound", page.text), n=1)
# set read to yes if start signal was recognised
if(length(start_pos) == 1){
read <- "yes"
}
# read table data from page
if(read == "yes"){
# increase run number
run <- run + 1
# first run
if(run == 1){
# subset page text vector
page.text.table <- page.text[(start_pos+1):(length(page.text)-1)]
}
# further runs
if(run > 1){
# subset page text vector
page.text.table <- page.text[6:(length(page.text)-1)]
}
# extract relavant information
# extract Compound names
# remove double spaces and insert '\t' as wildcard
page.text.table.corrected <- gsub(' {2,}','\t',page.text.table)
# convert character vector into dataframe
page.text.df <- data.frame(page.text.table.corrected)
# add column name
colnames(page.text.df) <- c("Compound")
# expand dataframe using column seperation based on wildcard
page.text.df <- separate(page.text.df, Compound, into = as.character(c(1:10)), sep='\t')
# select columns of interest
page.text.df.final <- select(page.text.df, 1)
# adjust column names
colnames(page.text.df.final) <- c("Compound")
# add RT and Response data
page.text.df.final$RT <- str_extract(string = page.text.table, pattern = "\\s[0-9]{1,}[.][0-9]{2}\\s")
page.text.df.final$Response <- str_extract(string = page.text.table, pattern = "\\s[0-9]{2,}\\s")
# create full dataframe from pdf table
if(run == 1){
final.table <- page.text.df.final
}
# add data from further pages to final dataframe
if(run > 1){
final.table <- rbind(final.table, page.text.df.final)
}
# create output dir
dir.create(file.path(outfolder,"pdf2tsv"))
# save extracted data from pdf file as .tsv file
write.table(final.table, file.path(outfolder,"pdf2tsv", paste0(date,"_",basename(files[file]),".tsv")), quote = F, col.names = T, row.names = F, sep = '\t', na = "")
}
}
# concatenate tables from different files into list format
file.list <- c()
file.list[[file]] <- final.table
}
# Inform user about pdf to tsv conversion and ask if data looks good to proceed (GUI)
out <- tk_messageBox(type = "yesnocancel", message = "Note: .pdf to .tsv conversion completed successfully. \n\nPlease check the created .tsv files. \n\nDo they contain the correct information? \n\n(Yes: Analysis will be continued) \n(No: Please adjust .tsv files and restart)"
, caption = "Question", default = "")
## Alternative: Inform user about pdf to tsv conversion and ask if data looks good to proceed (R terminal)
#out <- if (interactive()){
#  askYesNo("Note: .pdf to .tsv conversion completed successfully. Please check the created .tsv files. \nQuestion: Do they contain the correct information? \n          (Yes: .tsv files will be used automatically for further analysis)\n          (no: Please adjust .tsv files and restart program using the adjusted files) ")
#}
# if data as not okay or question was canceled stop program
if(out != TRUE | is.na(out)){
stop(str_c("Program was stopped to be restarted with the adjusted .tsv files."))
}
}
## Step 1.2: read excel and convert to csv
if(file_format == "xlsx"){
file.list <- lapply(files, read.xlsx, sheet = 1, rowNames = TRUE, colNames = TRUE, skipEmptyRows = TRUE, skipEmptyCols = TRUE, na.strings = "NA")
# Ask user whether input is in Shimatzu format
form <- tk_messageBox(type = "yesno", message = "Are the selected .xlsx files already in the standard 3 tab format. \n\nYES: Theses are manually curated files of correct format.  \n\nNo: These files are in Shimadzu format and need adjustment."
, caption = "Question", default = "")
}
## Step 1.3: load csv data
if(file_format == "csv"){
file.list <- lapply(files, read_csv, col_names = TRUE)
}
## Step 1.4: load tsv or txt data
if(file_format == "tsv" | file_format == "txt"){
file.list <- lapply(files, read_tsv, na = c("", "NA"), col_names = TRUE)
}
# check if data format needs correction
if(exists("form") & form != TRUE){
## correction of file.list data in case data is in Shimadzu ourput format:
for (file in 1:length(files)){
df <- file.list[[file]]
#adjust column names
colnames(df) <- df[7,]
# remove header lines
df = df[-(1:7),]
#correct column nmaes
df$RT <- df$Ret.Time
df$Response <- df$Area
df$Compound <- df$Name
#select required data
subset <- select(df, Compound, RT, Response)
#correct fil.list entry
file.list[[file]] <- subset
}
}
View(file.list)
View(file.list[[1]])
list.of.packages = c("here","tidyverse","knitr","tcltk","readxl","matrixStats","openxlsx","tools","stringr","utils","pdftools","ggplot2","ggpubr","BBmisc","ggsci","scales","RColorBrewer")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages) > 0) {install.packages(new.packages)}
lapply(list.of.packages, require, character.only=T)
# Date
date <- format(Sys.Date(), format="%Y-%m-%d")
# GUI to allow user to selection working directory
wd <- tk_choose.dir(here(), caption = "Select your working directory")
setwd(wd)
# Name of the output directory (will be created in your current working directory)
outfolder <- file.path(str_c(date,"_GCSM-analysis-results"))
# create output dir
dir.create(outfolder)
# GUI to allow user selection
filters <- matrix(c("All accepted",".pdf .tsv .csv .xlsx .txt", "PDF files",".pdf","Comma seperated files",".csv","Tab seperated files",".tsv","Excel files" ,".xlsx","Text files",".txt", "All files", "*"), 7, 2, byrow = TRUE)
files <- tk_choose.files(caption = "Choose GCMS files to analyse", multi = TRUE, filter = filters)
# identify file type by extension
ext <- file_ext(files)
file_format <- unique(ext)
for (file in 1:length(files)){
# Report error if file format is wrong
if(!(ext[[file]] %in% c("pdf","xlsx","tsv","csv","txt")) ){
stop(str_c("Incorrect extension of file ",file,": Please select only files of supported format (.pdf,.xlsx,.tsv,.csv,.txt)."))
}
# Report error if not all files are of same format
if(length(file_format) > 1){
stop(str_c("Inconsitent file extensions. All files must be of same file format."))
}
}
## Step 1.1: read pdf and convert to tsv
if(file_format == "pdf"){
for (file in 1:length(files)){
# read pdf file and split into rows
pages <- pdf_text(files[file]) %>% strsplit(split = "\n")
# set read to default ("no")
read <- "no"
# set run counter to 0
run <- 0
# go through the pages and extract table information
for (p in 1:length(pages)){
# select text from a page
page.text<-pages[p][[1]]
#identify start position for text extraction based on grep result
start_pos <- tail(grep("Compound", page.text), n=1)
# set read to yes if start signal was recognised
if(length(start_pos) == 1){
read <- "yes"
}
# read table data from page
if(read == "yes"){
# increase run number
run <- run + 1
# first run
if(run == 1){
# subset page text vector
page.text.table <- page.text[(start_pos+1):(length(page.text)-1)]
}
# further runs
if(run > 1){
# subset page text vector
page.text.table <- page.text[6:(length(page.text)-1)]
}
# extract relavant information
# extract Compound names
# remove double spaces and insert '\t' as wildcard
page.text.table.corrected <- gsub(' {2,}','\t',page.text.table)
# convert character vector into dataframe
page.text.df <- data.frame(page.text.table.corrected)
# add column name
colnames(page.text.df) <- c("Compound")
# expand dataframe using column seperation based on wildcard
page.text.df <- separate(page.text.df, Compound, into = as.character(c(1:10)), sep='\t')
# select columns of interest
page.text.df.final <- select(page.text.df, 1)
# adjust column names
colnames(page.text.df.final) <- c("Compound")
# add RT and Response data
page.text.df.final$RT <- str_extract(string = page.text.table, pattern = "\\s[0-9]{1,}[.][0-9]{2}\\s")
page.text.df.final$Response <- str_extract(string = page.text.table, pattern = "\\s[0-9]{2,}\\s")
# create full dataframe from pdf table
if(run == 1){
final.table <- page.text.df.final
}
# add data from further pages to final dataframe
if(run > 1){
final.table <- rbind(final.table, page.text.df.final)
}
# create output dir
dir.create(file.path(outfolder,"pdf2tsv"))
# save extracted data from pdf file as .tsv file
write.table(final.table, file.path(outfolder,"pdf2tsv", paste0(date,"_",basename(files[file]),".tsv")), quote = F, col.names = T, row.names = F, sep = '\t', na = "")
}
}
# concatenate tables from different files into list format
file.list <- c()
file.list[[file]] <- final.table
}
# Inform user about pdf to tsv conversion and ask if data looks good to proceed (GUI)
out <- tk_messageBox(type = "yesnocancel", message = "Note: .pdf to .tsv conversion completed successfully. \n\nPlease check the created .tsv files. \n\nDo they contain the correct information? \n\n(Yes: Analysis will be continued) \n(No: Please adjust .tsv files and restart)"
, caption = "Question", default = "")
## Alternative: Inform user about pdf to tsv conversion and ask if data looks good to proceed (R terminal)
#out <- if (interactive()){
#  askYesNo("Note: .pdf to .tsv conversion completed successfully. Please check the created .tsv files. \nQuestion: Do they contain the correct information? \n          (Yes: .tsv files will be used automatically for further analysis)\n          (no: Please adjust .tsv files and restart program using the adjusted files) ")
#}
# if data as not okay or question was canceled stop program
if(out != TRUE | is.na(out)){
stop(str_c("Program was stopped to be restarted with the adjusted .tsv files."))
}
}
## Step 1.2: read excel and convert to csv
if(file_format == "xlsx"){
file.list <- lapply(files, read.xlsx, sheet = 1, rowNames = TRUE, colNames = TRUE, skipEmptyRows = TRUE, skipEmptyCols = TRUE, na.strings = "NA")
# Ask user whether input is in Shimatzu format
form <- tk_messageBox(type = "yesno", message = "Are the selected .xlsx files already in the standard 3 tab format. \n\nYES: Theses are manually curated files of correct format.  \n\nNo: These files are in Shimadzu format and need adjustment."
, caption = "Question", default = "")
}
list.of.packages = c("here","tidyverse","knitr","tcltk","readxl","matrixStats","openxlsx","tools","stringr","utils","pdftools","ggplot2","ggpubr","BBmisc","ggsci","scales","RColorBrewer")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages) > 0) {install.packages(new.packages)}
lapply(list.of.packages, require, character.only=T)
# Date
date <- format(Sys.Date(), format="%Y-%m-%d")
# GUI to allow user to selection working directory
wd <- tk_choose.dir(here(), caption = "Select your working directory")
# GUI to allow user to selection working directory
wd <- tk_choose.dir(here(), caption = "Select your working directory")
setwd(wd)
# Name of the output directory (will be created in your current working directory)
outfolder <- file.path(str_c(date,"_GCSM-analysis-results"))
# create output dir
dir.create(outfolder)
# GUI to allow user selection
filters <- matrix(c("All accepted",".pdf .tsv .csv .xlsx .txt", "PDF files",".pdf","Comma seperated files",".csv","Tab seperated files",".tsv","Excel files" ,".xlsx","Text files",".txt", "All files", "*"), 7, 2, byrow = TRUE)
files <- tk_choose.files(caption = "Choose GCMS files to analyse", multi = TRUE, filter = filters)
# identify file type by extension
ext <- file_ext(files)
file_format <- unique(ext)
for (file in 1:length(files)){
# Report error if file format is wrong
if(!(ext[[file]] %in% c("pdf","xlsx","tsv","csv","txt")) ){
stop(str_c("Incorrect extension of file ",file,": Please select only files of supported format (.pdf,.xlsx,.tsv,.csv,.txt)."))
}
# Report error if not all files are of same format
if(length(file_format) > 1){
stop(str_c("Inconsitent file extensions. All files must be of same file format."))
}
}
## Step 1.1: read pdf and convert to tsv
if(file_format == "pdf"){
for (file in 1:length(files)){
# read pdf file and split into rows
pages <- pdf_text(files[file]) %>% strsplit(split = "\n")
# set read to default ("no")
read <- "no"
# set run counter to 0
run <- 0
# go through the pages and extract table information
for (p in 1:length(pages)){
# select text from a page
page.text<-pages[p][[1]]
#identify start position for text extraction based on grep result
start_pos <- tail(grep("Compound", page.text), n=1)
# set read to yes if start signal was recognised
if(length(start_pos) == 1){
read <- "yes"
}
# read table data from page
if(read == "yes"){
# increase run number
run <- run + 1
# first run
if(run == 1){
# subset page text vector
page.text.table <- page.text[(start_pos+1):(length(page.text)-1)]
}
# further runs
if(run > 1){
# subset page text vector
page.text.table <- page.text[6:(length(page.text)-1)]
}
# extract relavant information
# extract Compound names
# remove double spaces and insert '\t' as wildcard
page.text.table.corrected <- gsub(' {2,}','\t',page.text.table)
# convert character vector into dataframe
page.text.df <- data.frame(page.text.table.corrected)
# add column name
colnames(page.text.df) <- c("Compound")
# expand dataframe using column seperation based on wildcard
page.text.df <- separate(page.text.df, Compound, into = as.character(c(1:10)), sep='\t')
# select columns of interest
page.text.df.final <- select(page.text.df, 1)
# adjust column names
colnames(page.text.df.final) <- c("Compound")
# add RT and Response data
page.text.df.final$RT <- str_extract(string = page.text.table, pattern = "\\s[0-9]{1,}[.][0-9]{2}\\s")
page.text.df.final$Response <- str_extract(string = page.text.table, pattern = "\\s[0-9]{2,}\\s")
# create full dataframe from pdf table
if(run == 1){
final.table <- page.text.df.final
}
# add data from further pages to final dataframe
if(run > 1){
final.table <- rbind(final.table, page.text.df.final)
}
# create output dir
dir.create(file.path(outfolder,"pdf2tsv"))
# save extracted data from pdf file as .tsv file
write.table(final.table, file.path(outfolder,"pdf2tsv", paste0(date,"_",basename(files[file]),".tsv")), quote = F, col.names = T, row.names = F, sep = '\t', na = "")
}
}
# concatenate tables from different files into list format
file.list <- c()
file.list[[file]] <- final.table
}
# Inform user about pdf to tsv conversion and ask if data looks good to proceed (GUI)
out <- tk_messageBox(type = "yesnocancel", message = "Note: .pdf to .tsv conversion completed successfully. \n\nPlease check the created .tsv files. \n\nDo they contain the correct information? \n\n(Yes: Analysis will be continued) \n(No: Please adjust .tsv files and restart)"
, caption = "Question", default = "")
## Alternative: Inform user about pdf to tsv conversion and ask if data looks good to proceed (R terminal)
#out <- if (interactive()){
#  askYesNo("Note: .pdf to .tsv conversion completed successfully. Please check the created .tsv files. \nQuestion: Do they contain the correct information? \n          (Yes: .tsv files will be used automatically for further analysis)\n          (no: Please adjust .tsv files and restart program using the adjusted files) ")
#}
# if data as not okay or question was canceled stop program
if(out != TRUE | is.na(out)){
stop(str_c("Program was stopped to be restarted with the adjusted .tsv files."))
}
}
## Step 1.2: read excel and convert to csv
if(file_format == "xlsx"){
file.list <- lapply(files, read.xlsx, sheet = 1, rowNames = TRUE, colNames = TRUE, skipEmptyRows = TRUE, skipEmptyCols = TRUE, na.strings = "NA")
# Ask user whether input is in Shimatzu format
form <- tk_messageBox(type = "yesno", message = "Are the selected .xlsx files already in the standard 3 tab format. \n\nYES: Theses are manually curated files of correct format.  \n\nNo: These files are in Shimadzu format and need adjustment."
, caption = "Question", default = "")
}
## Step 1.3: load csv data
if(file_format == "csv"){
file.list <- lapply(files, read_csv, col_names = TRUE)
}
## Step 1.4: load tsv or txt data
if(file_format == "tsv" | file_format == "txt"){
file.list <- lapply(files, read_tsv, na = c("", "NA"), col_names = TRUE)
}
# check if data format needs correction
if(exists("form") & form != TRUE){
## correction of file.list data in case data is in Shimadzu ourput format:
for (file in 1:length(files)){
df <- file.list[[file]]
#adjust column names
colnames(df) <- df[7,]
# remove header lines
df = df[-(1:7),]
#correct column nmaes
df$RT <- df$Ret.Time
df$Response <- df$Area
df$Compound <- df$Name
#select required data
subset <- select(df, Compound, RT, Response)
#correct fil.list entry
file.list[[file]] <- subset
}
}
View(file.list)
View(file.list)
View(file.list[[1]])
form
# check if data format needs correction
if(exists("form") & form != "yes"){
## correction of file.list data in case data is in Shimadzu ourput format:
for (file in 1:length(files)){
df <- file.list[[file]]
#adjust column names
colnames(df) <- df[7,]
# remove header lines
df = df[-(1:7),]
#correct column nmaes
df$RT <- df$Ret.Time
df$Response <- df$Area
df$Compound <- df$Name
#select required data
subset <- select(df, Compound, RT, Response)
#correct fil.list entry
file.list[[file]] <- subset
}
}
source('~/Documents/GitHub/GCMS-data-extraction-tool/scripts/MetaPLMA_main-anaylsis-script.R')
View(file.list)
View(file.list)
View(file.list[[1]])
source('~/Documents/GitHub/GCMS-data-extraction-tool/scripts/MetaPLMA_main-anaylsis-script.R')
View(matrix.RT.ordered)
View(matrix.RT.ordered)
source('~/Documents/GitHub/GCMS-data-extraction-tool/scripts/MetaPLMA_main-anaylsis-script.R')
View(subset)
